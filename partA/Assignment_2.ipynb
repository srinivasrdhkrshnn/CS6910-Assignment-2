{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinivasrdhkrshnn/CS6910-Assignment-2/blob/main/partA/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ4alvF1PJKc"
      },
      "source": [
        "src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "src_zip = \"nature_12K.zip\"\n",
        "DATA_TRAIN_SRC = \"inaturalist_12K/train\" \n",
        "DATA_TEST_SRC = \"inaturalist_12K/val\"\n",
        "TRAIN_IMAGES_PER_LABEL = 1000\n",
        "TEST_IMAGES_PER_LABEL = 200\n",
        "BALANCED_SPLITS = {\"train\" : 900, \"val\" : 100}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmkELlpPQHJ"
      },
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!unzip $src_zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3A62DDWPxTf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "\n",
        "!pip3 install tensorflow -qqq\n",
        "!pip3 install wandb -qqq\n",
        "import wandb\n",
        "!wandb login\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3hRW3jH98mZ"
      },
      "source": [
        "PROJECT_NAME = \"CS6910 ASSIGNMENT 2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa2NBeWiP43D"
      },
      "source": [
        "**Upload Raw Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIgV7Ef9P9cM"
      },
      "source": [
        "# source directory for all raw train data\n",
        "SRC_TRAIN = DATA_TRAIN_SRC\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = TRAIN_IMAGES_PER_LABEL * 10\n",
        "PREFIX_1 = \"train\" # convenient for tracking local data\n",
        "\n",
        "TRAIN_RAW_DATA_AT = \"_\".join([PREFIX_1, \"raw_data\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, entity='cs6910krsrd',job_type=\"upload\")\n",
        "\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(TRAIN_RAW_DATA_AT, type=\"raw_data\")\n",
        "\n",
        "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
        "# each folder contains images of the corresponding class\n",
        "labels = os.listdir(SRC_TRAIN)\n",
        "for l in labels:\n",
        "  imgs_per_label = os.path.join(SRC_TRAIN, l)\n",
        "  if os.path.isdir(imgs_per_label):\n",
        "    imgs = os.listdir(imgs_per_label)\n",
        "    # randomize the order\n",
        "    shuffle(imgs)\n",
        "    img_file_ids = imgs[:TRAIN_IMAGES_PER_LABEL]\n",
        "    for f in img_file_ids:\n",
        "      file_path = os.path.join(SRC_TRAIN, l, f)\n",
        "      # add file to artifact by full path\n",
        "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYLO8XNzQJZL"
      },
      "source": [
        "**Upload Raw Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRNOd-uYQKpC"
      },
      "source": [
        "# source directory for all raw train data\n",
        "SRC_TEST = DATA_TEST_SRC\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = TEST_IMAGES_PER_LABEL * 10\n",
        "PREFIX_2 = \"test\" # convenient for tracking local data\n",
        "\n",
        "TEST_RAW_DATA_AT = \"_\".join([PREFIX_2, \"raw_data\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, entity='cs6910krsrd', job_type=\"upload\")\n",
        "\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(TEST_RAW_DATA_AT, type=\"raw_data\")\n",
        "\n",
        "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
        "# each folder contains images of the corresponding class\n",
        "labels = os.listdir(SRC_TEST)\n",
        "for l in labels:\n",
        "  imgs_per_label = os.path.join(SRC_TEST, l)\n",
        "  if os.path.isdir(imgs_per_label):\n",
        "    imgs = os.listdir(imgs_per_label)\n",
        "    # randomize the order\n",
        "    shuffle(imgs)\n",
        "    img_file_ids = imgs[:TEST_IMAGES_PER_LABEL]\n",
        "    for f in img_file_ids:\n",
        "      file_path = os.path.join(SRC_TEST, l, f)\n",
        "      # add file to artifact by full path\n",
        "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNjFxxCQOYx"
      },
      "source": [
        "**Split Train Data into Train and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7jiHiPkQScG"
      },
      "source": [
        "run = wandb.init(project=PROJECT_NAME, entity='cs6910krsrd',job_type=\"data_split\")\n",
        "\n",
        "# find the most recent (\"latest\") version of the full raw data\n",
        "# you can of course pass around programmatic aliases and not string literals\n",
        "data_at = run.use_artifact(TRAIN_RAW_DATA_AT + \":latest\")\n",
        "# download it locally (for illustration purposes/across hardware; you can\n",
        "# also sync/version artifacts by reference)\n",
        "data_dir = data_at.download()\n",
        "\n",
        "# create balanced train, val, test splits\n",
        "# each count is the number of images per label\n",
        "DATA_SPLITS = BALANCED_SPLITS\n",
        "\n",
        "ats = {}\n",
        "# wrap artifacts in dictionary for convenience\n",
        "for split, count in DATA_SPLITS.items():\n",
        "  ats[split] = wandb.Artifact(\"_\".join([PREFIX_1, split, \"data\", str(count*10)]), \n",
        "                              \"_\".join([split, \"data\"]))\n",
        "\n",
        "labels = os.listdir(data_dir)\n",
        "for l in labels:\n",
        "  if l.startswith(\".\"): # skip non-label file\n",
        "    continue\n",
        "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
        "  shuffle(imgs_per_label)\n",
        "  start_id = 0\n",
        "  for split, count in DATA_SPLITS.items():\n",
        "    # take a subset\n",
        "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
        "    for img_file in split_imgs:\n",
        "      full_path = os.path.join(data_dir, l, img_file)\n",
        "      # add file to artifact by full path\n",
        "      # note: pass the label to the name parameter to retain it in\n",
        "      # the data structure \n",
        "      ats[split].add_file(full_path, name = os.path.join(l, img_file))\n",
        "    start_id += count\n",
        "\n",
        "# save all three artifacts to W&B\n",
        "# note: yes, in this example, we are cheating and have labels for the \"val\" data ;)\n",
        "for split, artifact in ats.items():\n",
        "  run.log_artifact(artifact)\n",
        "\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts9vO5gjQkEC"
      },
      "source": [
        "**Default Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKGymf0TQuiZ"
      },
      "source": [
        "MODEL_NAME = \"CNN\"\n",
        "FINAL_MODEL_DIR = \"trained_CNN\"\n",
        "\n",
        "\n",
        "n_train = BALANCED_SPLITS[\"train\"] * 10\n",
        "n_val = BALANCED_SPLITS[\"val\"] * 10\n",
        "n_epochs = 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcUa0BxaQ4yG"
      },
      "source": [
        "**Define and Compile Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hea7B2_1Q5rl"
      },
      "source": [
        "def cnn_model_1(img_size,n_filters,filter_size,fc_size,drop_out,n_classes):\n",
        "\n",
        "   model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(n_filters[0], (filter_size[0],filter_size[0]), activation='relu', input_shape=(img_size,img_size,3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[1], (filter_size[1],filter_size[1]), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[2], (filter_size[2],filter_size[2]), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[3], (filter_size[3],filter_size[3]), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[4], (filter_size[4],filter_size[4]), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(fc_size, activation='relu'),\n",
        "        tf.keras.layers.Dense(n_classes,activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "   model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "   model.summary()\n",
        "   return model\n",
        "\n",
        "def cnn_model_2(img_size,n_filters,filter_size,fc_size,drop_out,n_classes):\n",
        "\n",
        "   model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(n_filters[0], (filter_size[0],filter_size[0]), activation='relu', input_shape=(img_size,img_size,3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[1], (filter_size[1],filter_size[1]), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[2], (filter_size[2],filter_size[2]), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[3], (filter_size[3],filter_size[3]), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(n_filters[4], (filter_size[4],filter_size[4]), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(fc_size, activation='relu'),\n",
        "        tf.keras.layers.Dense(n_classes,activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "   model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "   model.summary()\n",
        "   return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qL6dgo8Q9tv"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQwJcV3_RABD"
      },
      "source": [
        "def train():\n",
        "\n",
        "  config_defaults[\"filter_size_val\"]=0\n",
        "  # track this experiment with wandb: all runs will be sent to the given project name\n",
        "  run = wandb.init(config=config_defaults,entity='cs6910krsrd',job_type='train')\n",
        "  cfg = wandb.config\n",
        "\n",
        "  # artifact names\n",
        "  train_at = os.path.join(PROJECT_NAME, PREFIX_1 + \"_train_data_\" + str(n_train)) + \":latest\"\n",
        "  val_at = os.path.join(PROJECT_NAME, PREFIX_1 + \"_val_data_\" + str(n_val)) + \":latest\"\n",
        "\n",
        "  train_data = run.use_artifact(train_at, type='train_data')\n",
        "  train_dir = train_data.download()\n",
        "  val_data = run.use_artifact(val_at, type='val_data')\n",
        "  val_dir = val_data.download()\n",
        "\n",
        "  # create augmented train and validation data generators\n",
        "  if cfg.augmentation == 1:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=36,\n",
        "      shear_range=0.3,\n",
        "      zoom_range=0.4,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "  else  :\n",
        "    train_datagen = ImageDataGenerator(rescale = 1. /255)\n",
        "  \n",
        "  val_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(cfg.img_size, cfg.img_size),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(cfg.img_size, cfg.img_size),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical')\n",
        "  \n",
        "  # cfg.n_filters=[np.random.choice(cfg.n_filters_val) for i in range(5)]   #hidden layer sizes array creation\n",
        "\n",
        "  if cfg.filter_size_val!=0:\n",
        "    cfg.filter_size=[np.random.choice(cfg.filter_size_val) for i in range(5)]\n",
        "\n",
        "  # instantiate model and callbacks\n",
        "  if cfg.batch_normalize==1 :\n",
        "    model = cnn_model_1(cfg.img_size,cfg.n_filters,cfg.filter_size,cfg.fc_size,cfg.drop_out,cfg.n_classes)\n",
        "\n",
        "  elif cfg.batch_normalize==0 :\n",
        "    model = cnn_model_2(cfg.img_size,cfg.n_filters,cfg.filter_size,cfg.fc_size,cfg.drop_out,cfg.n_classes) \n",
        "  \n",
        " \n",
        "  # train and validate\n",
        "  history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch = n_train // cfg.batch_size,\n",
        "      epochs = n_epochs,\n",
        "      validation_data=val_generator,\n",
        "      callbacks = [WandbCallback()],\n",
        "      validation_steps = n_val // cfg.batch_size)\n",
        "\n",
        "  # save trained model as artifact\n",
        "  trained_model_artifact = wandb.Artifact(\n",
        "            MODEL_NAME, type=\"model\",\n",
        "            description=\"trained cnn model\",\n",
        "            metadata=dict(cfg))\n",
        "\n",
        "  model.save(FINAL_MODEL_DIR)\n",
        "  trained_model_artifact.add_dir(FINAL_MODEL_DIR)\n",
        "  run.log_artifact(trained_model_artifact)\n",
        "  run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvxSYb31aBvl"
      },
      "source": [
        "def sweeper(sweep_config,PROJECT_NAME):\n",
        "  sweep_id=wandb.sweep(sweep_config,project=PROJECT_NAME,entity='cs6910krsrd',)\n",
        "  wandb.agent(sweep_id,train,project=PROJECT_NAME,entity='cs6910krsrd',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW9vucYHaF3j"
      },
      "source": [
        "#sweep dictionary\n",
        "sweep_config={\n",
        "    'method':'bayes',\n",
        "    'metric':{\n",
        "        'name':'val_accuracy',\n",
        "        'goal':'maximize'},\n",
        "\n",
        "}\n",
        "\n",
        "parameters_dict={\n",
        "    \n",
        "    'n_filters':{\n",
        "        'values':[[64,64,81,128,225],[49,64,96,121,169]] # ,[36,49,64,64,121],[36,49,49,81,144]\n",
        "    },\n",
        "    'filter_size_val':{\n",
        "        'values':[[1,2,3,5]]\n",
        "    },\n",
        "    'fc_size':{\n",
        "        'values':[256,512,1024]\n",
        "    },\n",
        "    'drop_out':{\n",
        "        'values':[0.5,0.7,0.4,0.6,0,0.1]\n",
        "    },\n",
        "    'augmentation':{\n",
        "      'values':[1] \n",
        "    },\n",
        "    'batch_normalize':{\n",
        "        'values':[1]\n",
        "    },\n",
        "    'batch_size':{\n",
        "        'values':[64]\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters']=parameters_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMzwRRtfu1IN"
      },
      "source": [
        "config_defaults = {\n",
        "    \"img_size\" : 229,\n",
        "    \"batch_size\" : 100,\n",
        "    \"n_classes\" : 10,\n",
        "    \"n_filters\" : [16,32,64,64,128],\n",
        "    \"filter_size\" : [3,3,3,3,3],\n",
        "    \"fc_size\" : 400,\n",
        "    \"drop_out\" : 0.5,\n",
        "    \"augmentation\" : 1,\n",
        "    \"batch_normalize\" : 1 \n",
        "}\n",
        "\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSVkYkeqaLPg"
      },
      "source": [
        "#sweeper(sweep_config,PROJECT_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}