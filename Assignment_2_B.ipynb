{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinivasrdhkrshnn/CS6910-Assignment-2/blob/main/Assignment_2_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ4alvF1PJKc"
      },
      "source": [
        "src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "src_zip = \"nature_12K.zip\"\n",
        "DATA_TRAIN_SRC = \"inaturalist_12K/train\" \n",
        "DATA_TEST_SRC = \"inaturalist_12K/val\"\n",
        "TRAIN_IMAGES_PER_LABEL = 1000\n",
        "TEST_IMAGES_PER_LABEL = 200\n",
        "BALANCED_SPLITS = {\"train\" : 900, \"val\" : 100}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmkELlpPQHJ"
      },
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!unzip $src_zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk8BFH6tDjuk"
      },
      "source": [
        "**Import Libraries & Install, Import WandB Library and Login to WandB account**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3A62DDWPxTf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "\n",
        "!pip3 install tensorflow -qqq\n",
        "!pip3 install wandb -qqq\n",
        "import wandb\n",
        "!wandb login\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3hRW3jH98mZ"
      },
      "source": [
        "PROJECT_NAME = \"CS6910 ASSIGNMENT 2B\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa2NBeWiP43D"
      },
      "source": [
        "**Upload Raw Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIgV7Ef9P9cM"
      },
      "source": [
        "# source directory for all raw train data\n",
        "SRC_TRAIN = DATA_TRAIN_SRC\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = TRAIN_IMAGES_PER_LABEL * 10\n",
        "PREFIX_1 = \"train\" # convenient for tracking local data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_5ER4HaNY21"
      },
      "source": [
        "TRAIN_RAW_DATA_AT = \"_\".join([PREFIX_1, \"raw_data\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, job_type=\"upload\")\n",
        "\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(TRAIN_RAW_DATA_AT, type=\"raw_data\")\n",
        "\n",
        "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
        "# each folder contains images of the corresponding class\n",
        "labels = os.listdir(SRC_TRAIN)\n",
        "for l in labels:\n",
        "  imgs_per_label = os.path.join(SRC_TRAIN, l)\n",
        "  if os.path.isdir(imgs_per_label):\n",
        "    imgs = os.listdir(imgs_per_label)\n",
        "    # randomize the order\n",
        "    shuffle(imgs)\n",
        "    img_file_ids = imgs[:TRAIN_IMAGES_PER_LABEL]\n",
        "    for f in img_file_ids:\n",
        "      file_path = os.path.join(SRC_TRAIN, l, f)\n",
        "      # add file to artifact by full path\n",
        "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYLO8XNzQJZL"
      },
      "source": [
        "**Upload Raw Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRNOd-uYQKpC"
      },
      "source": [
        "# source directory for all raw train data\n",
        "SRC_TEST = DATA_TEST_SRC\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = TEST_IMAGES_PER_LABEL * 10\n",
        "PREFIX_2 = \"test\" # convenient for tracking local data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjNRk4vNbV5"
      },
      "source": [
        "TEST_RAW_DATA_AT = \"_\".join([PREFIX_2, \"raw_data\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, job_type=\"upload\")\n",
        "\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(TEST_RAW_DATA_AT, type=\"raw_data\")\n",
        "\n",
        "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
        "# each folder contains images of the corresponding class\n",
        "labels = os.listdir(SRC_TEST)\n",
        "for l in labels:\n",
        "  imgs_per_label = os.path.join(SRC_TEST, l)\n",
        "  if os.path.isdir(imgs_per_label):\n",
        "    imgs = os.listdir(imgs_per_label)\n",
        "    # randomize the order\n",
        "    shuffle(imgs)\n",
        "    img_file_ids = imgs[:TEST_IMAGES_PER_LABEL]\n",
        "    for f in img_file_ids:\n",
        "      file_path = os.path.join(SRC_TEST, l, f)\n",
        "      # add file to artifact by full path\n",
        "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNjFxxCQOYx"
      },
      "source": [
        "**Split Train Data into Train and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7jiHiPkQScG"
      },
      "source": [
        "run = wandb.init(project=PROJECT_NAME, job_type=\"data_split\")\n",
        "\n",
        "# find the most recent (\"latest\") version of the full raw data\n",
        "# you can of course pass around programmatic aliases and not string literals\n",
        "data_at = run.use_artifact(TRAIN_RAW_DATA_AT + \":latest\")\n",
        "# download it locally (for illustration purposes/across hardware; you can\n",
        "# also sync/version artifacts by reference)\n",
        "data_dir = data_at.download()\n",
        "\n",
        "# create balanced train, val, test splits\n",
        "# each count is the number of images per label\n",
        "DATA_SPLITS = BALANCED_SPLITS\n",
        "\n",
        "ats = {}\n",
        "# wrap artifacts in dictionary for convenience\n",
        "for split, count in DATA_SPLITS.items():\n",
        "  ats[split] = wandb.Artifact(\"_\".join([PREFIX_1, split, \"data\", str(count*10)]), \n",
        "                              \"_\".join([split, \"data\"]))\n",
        "\n",
        "labels = os.listdir(data_dir)\n",
        "for l in labels:\n",
        "  if l.startswith(\".\"): # skip non-label file\n",
        "    continue\n",
        "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
        "  shuffle(imgs_per_label)\n",
        "  start_id = 0\n",
        "  for split, count in DATA_SPLITS.items():\n",
        "    # take a subset\n",
        "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
        "    for img_file in split_imgs:\n",
        "      full_path = os.path.join(data_dir, l, img_file)\n",
        "      # add file to artifact by full path\n",
        "      # note: pass the label to the name parameter to retain it in\n",
        "      # the data structure \n",
        "      ats[split].add_file(full_path, name = os.path.join(l, img_file))\n",
        "    start_id += count\n",
        "\n",
        "# save all three artifacts to W&B\n",
        "# note: yes, in this example, we are cheating and have labels for the \"val\" data ;)\n",
        "for split, artifact in ats.items():\n",
        "  run.log_artifact(artifact)\n",
        "\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts9vO5gjQkEC"
      },
      "source": [
        "**Default Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKGymf0TQuiZ"
      },
      "source": [
        "\n",
        "n_train = BALANCED_SPLITS[\"train\"] * 10\n",
        "n_val = BALANCED_SPLITS[\"val\"] * 10\n",
        "n_epochs = 7\n",
        "img_size = 229\n",
        "batchsize = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcUa0BxaQ4yG"
      },
      "source": [
        "**Define and Compile Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hea7B2_1Q5rl"
      },
      "source": [
        "def cnn_model(fc_size,pretrained_model):\n",
        "   \n",
        "\n",
        "   if pretrained_model=='InceptionV3':\n",
        "     base = tf.keras.applications.InceptionV3(include_top=False,input_shape=(img_size,img_size,3),weights='imagenet')\n",
        "   elif pretrained_model=='Xception':\n",
        "     base = tf.keras.applications.Xception(include_top=False,input_shape=(img_size,img_size,3),weights='imagenet')\n",
        "   elif pretrained_model=='ResNet50':\n",
        "     base = tf.keras.applications.ResNet50(include_top=False,input_shape=(img_size,img_size,3),weights='imagenet')\n",
        "   elif pretrained_model=='InceptionResNetV2':\n",
        "     base = tf.keras.applications.InceptionResNetV2(include_top=False,input_shape=(img_size,img_size,3),weights='imagenet')\n",
        "   elif pretrained_model=='MobileNetV2':\n",
        "     base = tf.keras.applications.MobileNetV2(include_top=False,input_shape=(img_size,img_size,3),weights='imagenet')      \n",
        "   else:\n",
        "     raise Exception('no pretrained model given')\n",
        "   \n",
        "   for layer in base.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        "   x = base.output\n",
        "   x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "   x = tf.keras.layers.Dense(fc_size, activation='relu')(x)\n",
        "   prediction = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "   model = Model(inputs=base.input, outputs=prediction)\n",
        "  \n",
        "   model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "   model.summary()\n",
        "   return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qL6dgo8Q9tv"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQwJcV3_RABD"
      },
      "source": [
        "def train():\n",
        "  \n",
        "  config_defaults = {\n",
        "      \"model_name\" : \"InceptionV3\",\n",
        "      \"fc_size\" : 1024,\n",
        "      \"augmentation\" : 1,\n",
        "  }\n",
        "\n",
        "  # track this experiment with wandb: all runs will be sent to the given project name\n",
        "  run = wandb.init(config=config_defaults,job_type='train')\n",
        "  cfg = wandb.config\n",
        "  \n",
        "\n",
        "  MODEL_NAME = cfg.model_name \n",
        "  INIT_MODEL_DIR = \"init_model_\" + cfg.model_name\n",
        "  FINAL_MODEL_DIR = \"final_model_\" + cfg.model_name\n",
        "\n",
        "  # artifact names\n",
        "  train_at = os.path.join(PROJECT_NAME, PREFIX_1 + \"_train_data_\" + str(n_train)) + \":latest\"\n",
        "  val_at = os.path.join(PROJECT_NAME, PREFIX_1 + \"_val_data_\" + str(n_val)) + \":latest\"\n",
        "\n",
        "  train_data = run.use_artifact(train_at, type='train_data')\n",
        "  train_dir = train_data.download()\n",
        "  val_data = run.use_artifact(val_at, type='val_data')\n",
        "  val_dir = val_data.download()\n",
        "\n",
        "  # create augmented train and validation data generators\n",
        "  if cfg.augmentation == 1:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=36,\n",
        "      shear_range=0.3,\n",
        "      zoom_range=0.4,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "  else  :\n",
        "    train_datagen = ImageDataGenerator(rescale = 1. /255)\n",
        "  \n",
        "  val_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_size,img_size),\n",
        "    batch_size = batchsize,\n",
        "    class_mode='categorical')\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_size,img_size),\n",
        "    batch_size = batchsize,\n",
        "    class_mode='categorical')\n",
        "  \n",
        "\n",
        "  # instantiate model and callbacks\n",
        "  model = cnn_model(cfg.fc_size,cfg.model_name)\n",
        "\n",
        "  model_artifact = wandb.Artifact(\n",
        "            cfg.model_name, type=\"model\",\n",
        "            description=\"unmodified model\",\n",
        "            metadata=dict(cfg))\n",
        "\n",
        "  model.save(INIT_MODEL_DIR)\n",
        "  model_artifact.add_dir(INIT_MODEL_DIR)\n",
        "  run.log_artifact(model_artifact)\n",
        "  callbacks = [WandbCallback()]\n",
        " \n",
        "  # train and validate\n",
        "  model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch = n_train // batchsize,\n",
        "      epochs = n_epochs,\n",
        "      validation_data=val_generator,\n",
        "      callbacks = [WandbCallback()],\n",
        "      validation_steps = n_val // batchsize\n",
        "      )\n",
        "\n",
        "  # save trained model as artifact\n",
        "  trained_model_artifact = wandb.Artifact(\n",
        "            MODEL_NAME, type=\"model\",\n",
        "            description=\"finetuned model\",\n",
        "            metadata=dict(cfg))\n",
        "\n",
        "  model.save(FINAL_MODEL_DIR)\n",
        "  trained_model_artifact.add_dir(FINAL_MODEL_DIR)\n",
        "  run.log_artifact(trained_model_artifact)\n",
        "  run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x80_R2AJ2A7u"
      },
      "source": [
        "def sweeper(sweep_config,PROJECT_NAME):\n",
        "  sweep_id=wandb.sweep(sweep_config,project=PROJECT_NAME)\n",
        "  wandb.agent(sweep_id,train,project=PROJECT_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D-_9ZOd2ES9"
      },
      "source": [
        "#sweep dictionary\n",
        "sweep_config={\n",
        "    'method':'bayes',\n",
        "    'metric':{\n",
        "        'name':'val_accuracy',\n",
        "        'goal':'maximize'},\n",
        "\n",
        "}\n",
        "\n",
        "parameters_dict={\n",
        "    \n",
        "    'fc_size':{\n",
        "        'values':[1024,512,256]\n",
        "    },\n",
        "    \n",
        "    'augmentation':{\n",
        "      'values':[1]  \n",
        "    },\n",
        "    \n",
        "    'model_name':{\n",
        "        'values':['ResNet50','InceptionResNetV2','InceptionV3','Xception','MobileNetV2']\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters']=parameters_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kfz9Ea12HFs"
      },
      "source": [
        "sweeper(sweep_config,PROJECT_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}